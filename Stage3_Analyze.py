import os
import sys
import json
import time
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI  # å»ºè®®ä½¿ç”¨æ ‡å‡†åº“(æˆ–ä¿æŒä½ åŸæœ¬çš„init_chat_model)
from langchain.chat_models import init_chat_model
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è·¯å¾„é…ç½®
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROMPT_PATH = os.path.join(BASE_DIR, "prompts", "stage3.md")
DATA_PATH = os.path.join(BASE_DIR, "data", "stage3.json")
OUTPUTS_DIR = os.path.join(BASE_DIR, "outputs")
OUTPUT_FILE = os.path.join(OUTPUTS_DIR, "stage3_output.md")

def load_file_content(file_path: str) -> str:
    """é€šç”¨æ–‡ä»¶è¯»å–å‡½æ•°"""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()


def invoke_with_retry(chain, inputs: dict, max_retries: int = 3, delay: float = 2.0) -> str:
    for attempt in range(1, max_retries + 1):
        try:
            return chain.invoke(inputs)
        except Exception as e:
            print(f"âš ï¸ ç¬¬ {attempt} æ¬¡è°ƒç”¨ LLM å¤±è´¥: {e}")
            if attempt == max_retries:
                print("âŒ å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç»ˆæ­¢å½“å‰é˜¶æ®µã€‚")
                raise
            time.sleep(delay)

def run_agent():
    # 1. è¯»å– Prompt åŸå§‹å†…å®¹ (ä¸åš Python replaceï¼Œç›´æ¥äº¤ç»™ LangChain)
    prompt_text = load_file_content(PROMPT_PATH)
    
    # 2. è¯»å– JSON æ•°æ®å­—ç¬¦ä¸²
    json_data_obj = json.loads(load_file_content(DATA_PATH))
    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œç¡®ä¿ä¸å«ä¸­æ–‡ä¹±ç 
    json_data_str = json.dumps(json_data_obj, ensure_ascii=False, indent=2)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(OUTPUTS_DIR, exist_ok=True)

    # 3. åˆå§‹åŒ– LLM
    deepseek_api_key = os.getenv("DEEPSEEK_API_KEY")
    if not deepseek_api_key:
        raise EnvironmentError("è¯·é…ç½® DEEPSEEK_API_KEY")

    llm = init_chat_model(
        "deepseek-chat",
        model_provider="openai", # DeepSeek å…¼å®¹ OpenAI åè®®
        api_key=deepseek_api_key,
        base_url="https://api.deepseek.com",
        temperature=0.1,
    )

    # 4. æ„å»º Chain
    # æ³¨æ„ï¼šè¿™é‡Œç›´æ¥ä½¿ç”¨ from_templateï¼Œå®ƒä¼šè‡ªåŠ¨è§£æ prompt_text ä¸­çš„ {input_json}
    prompt_template = ChatPromptTemplate.from_template(prompt_text)
    output_parser = StrOutputParser()
    chain = prompt_template | llm | output_parser

    # 5. æ‰§è¡Œ Chain
    print("ğŸ¤– Agent æ­£åœ¨è¿›è¡Œç»è¥åˆ†æè¿ç®—ï¼ˆStage3ï¼‰...")
    try:
        result = invoke_with_retry(chain, {"input_json": json_data_str})

        with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
            f.write(result)

        print("-" * 30)
        print(f"ğŸ‰ æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼å·²ä¿å­˜è‡³: {OUTPUT_FILE}")
        print("-" * 30)
        print("é¢„è§ˆå†…å®¹ (å‰500å­—ç¬¦):\n")
        print(result[:500] + "...")

    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        sys.exit(1)

if __name__ == "__main__":
    run_agent()